Configure SQL Server resources for optimal performance

  Explain how to optimize Azure Storage for SQL Server virtual machine

    Azure Managed Disks
      Azure managed disks are block-level storage volumes that are presented to Azure Virtual Machines. Block level storage refers to raw volumes of storage that are created and can be treated as an individual hard drive. These block devices can be managed within the operating system, and the storage tier is not aware of the contents of the disk.

      Azure managed disks come in four types:

      Ultra disk - Ultra disks support high-IO workloads for mission critical databases with low latency.

      Premium SSD - Premium SSD disks are high-throughput and low latency and can meet the needs of most database workloads running in the cloud.

      Standard SSD - Standard SSDs are designed for lightly used dev/test workloads or web servers that do a small amount of IO, and require predictable latency.

      Standard HDD - Standard HDDs are suitable for backups and file storage that is infrequently accessed.

    Striping disk for maximum throughput
      One of the ways to get more performance and volume out of Azure disks is to stripe your data across multiple disks. This technique does not apply to Ultra disk, as you can scale IOPs, throughput, and maximum size independently on a single disk. However, with Premium SSDs it can be beneficial to scale both IOPs and storage volume. In order to stripe disks in Windows, you simply add the number of disks you would like to the VM, and then create a pool using Storage Spaces in Windows. Don't configure any redundancy for your pool (which would limit your performance) as the redundancy is provided by the Azure framework, which keeps three copies of all disks in synchronous replication to protect against a disk failure. When you create a pool, your pool has the sum of the IOPs and the sum of the volume of all the disks in your pool. For example, if you used 10 P30 disks that are each one TB and have 5000 IOPs per disk, you would have a 10-TB volume with 50,000 IOPs available.

    SQL Server configuration best practices
      There are few recommendations for best practices for SQL Server on Azure VMs and their storage configuration:

      Create a separate volume for data and transaction log files

      Enable read caching on the data file volume

      Do not enable any caching on the log file volume

      Plan for an additional 20% of IOPs and throughput when building your storage for your VM to handle workload peaks

      Use the D: drive (the locally attached SSD) for TempDB files because TempDB is recreated upon server restart, so there is no risk of data loss

      Enable instant file initialization to reduce the impact of file-growth activities.

      Move trace file and error log directories to data disks

      For workloads requiring storage latency under one millisecond, consider using Ultra disk over Premium SSD.

      Azure Virtual Machine resource provider

    Describe Virtual Machine resizing
      There are many size options for Azure Virtual Machines. For SQL Server workloads the main characteristics to look for are the amount of memory available, and the number of IOPs the virtual machine can perform. Azure has an option of using constrained core virtual machines, which can be useful for the following reason.

    Optimize Database Storage
      To optimize database storage, you should consider proportional fill and tempdb configuration.

      Proportion Fill : If you are inserting one gigabyte of data into a SQL Server database with two data files, you would expect the size of each of your data files to increase by roughly 512 megabytes. However, this equal growth is not necessarily the case, as SQL Server will insert data into data files in different volumes based on the size of the data file. In the above example, if your data files were both two gigabytes in size, you would expect the even distribution of data. However, if one of your data files was 10 gigabytes, and the other was one gigabyte, roughly 900 MB would go into the ten-gigabyte file, and 100 MB into the one-gigabyte file. While this behavior occurs in any database, with the write-intensive nature of tempdb, an uneven write pattern could cause a bottleneck on the largest file, as more of the writes would happen there.

    TempDB configuration in SQL Server
      SQL Server uses tempdb for much more than storing user-defined temporary tables. Work tables that are used to store intermediate query results, sorting operations, and the version store for row versioning are among just a few of the uses for tempdb. Because of this utilization, it is important both to place tempdb on the lowest latency storage possible, and to properly configure its data files.

    Control SQL Server Resources
      While some SQL Servers or Azure SQL managed instances only support one applicationâ€™s databases (this configuration is commonly seen in mission critical applications), many servers support databases for multiple applications with differing performance requirements and different peak workload cycles. Balancing these differing requirements can be challenging to the administrator. One of the ways to balance server resources is to use Resource Governor, which was introduced to SQL Server 2008.

      Resource Governor is a feature in SQL Server and Azure SQL managed instance that allows you to granularly control how much CPU, physical IO, and memory resources can be used by an incoming request from an application. Resource Governor is enabled at the instance level and allows you to define how connections are treated by using a classifier function, which subdivides sessions into workload group. Each workload group is configured to use a specific pool of system resources.

    Resource Pools
      A resource pool represents physical resources available on the server. SQL Server always has two pools, default and internal, even when Resource Governor is not enabled. The internal pool is used by critical SQL Server functions and cannot be restricted. The default pool, and any resource pools you explicitly define, can be configured with limits on the resources it can use. You can specify the following limits for each non-internal pool:

        Min/Max CPU percent
        Cap of CPU percent
        Min/Max memory percent
        NUMA node affinity
        Min/Max IOPs per volume

    Workload Group : A workload group is a container for session requests based on their classification by the classifier function. Like resource pools there are two built-in groups, default and internal, and each workload group can only belong to one resource pool. However, a resource pool can host multiple workload groups.

    Classifier Function : The classifier function is run at the time a connection is established to the SQL Server instance and classifies each connection into a given workload group. If the function returns a NULL, default, or the name of the non-existent workload group the session is transferred into the default workload group. 
